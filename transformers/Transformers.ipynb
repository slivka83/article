{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db0e799",
   "metadata": {},
   "source": [
    "# Использование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db64611",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fc3db0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T07:47:36.425408Z",
     "start_time": "2022-12-09T07:47:30.607323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neutral', 'score': 0.9872767329216003},\n",
       " {'label': 'toxic', 'score': 0.985331654548645}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline('sentiment-analysis', model='SkolkovoInstitute/russian_toxicity_classifier')\n",
    "\n",
    "text = ['У нас в есть убунты и текникал превью.',\n",
    "        'Как минимум два малолетних дегенерата в треде, мда.']\n",
    "\n",
    "clf(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e83961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T07:50:15.638299Z",
     "start_time": "2022-12-09T07:50:09.046648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.question_answering.QuestionAnsweringPipeline at 0x7fc057f79490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline('question-answering', model='distilbert-base-cased-distilled-squad', tokenizer='bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3444dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T07:52:06.053264Z",
     "start_time": "2022-12-09T07:52:03.973746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'neutral', 'score': 0.9872767329216003},\n",
       "  {'label': 'toxic', 'score': 0.012723307125270367}],\n",
       " [{'label': 'toxic', 'score': 0.985331654548645},\n",
       "  {'label': 'neutral', 'score': 0.01466838177293539}]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline('sentiment-analysis', model='SkolkovoInstitute/russian_toxicity_classifier')\n",
    "\n",
    "text = ['У нас в есть убунты и текникал превью.',\n",
    "        'Как минимум два малолетних дегенерата в треде, мда.']\n",
    "\n",
    "clf(text, top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f22d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T07:52:12.396901Z",
     "start_time": "2022-12-09T07:52:10.367787Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'neutral', 'score': 0.9872767329216003}\n",
      "{'label': 'toxic', 'score': 0.985331654548645}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline('sentiment-analysis', model='SkolkovoInstitute/russian_toxicity_classifier')\n",
    "\n",
    "text = ['У нас в есть убунты и текникал превью.',\n",
    "        'Как минимум два малолетних дегенерата в треде, мда.']\n",
    "\n",
    "def data(text):\n",
    "    for row in text:\n",
    "        yield row\n",
    "\n",
    "for out in clf(data(text)):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c1c64",
   "metadata": {},
   "source": [
    "## torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "254fdb64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T14:25:51.048333Z",
     "start_time": "2022-12-08T14:25:48.178824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 - tabby, tabby cat\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "response = requests.get(\n",
    "    'https://github.com/laxmimerit/dog-cat-full-dataset/blob/master/data/train/cats/cat.10055.jpg?raw=true')\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "feature_extractor = AutoImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = AutoModelForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = feature_extractor(img, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_id = logits.argmax(-1).item()\n",
    "predicted_label = model.config.id2label[predicted_id]\n",
    "print(predicted_id, '-', predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a7f9d1",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f3bb0",
   "metadata": {},
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f566667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T08:33:34.650819Z",
     "start_time": "2022-12-09T08:33:32.198771Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f5be76e4134573889b83dd003b5ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d398ba147a74e20b34bafd09a334b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "df = pd.read_csv('toxic.csv').sample(1000)\n",
    "df.columns = ['text','label']\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "train = Dataset.from_pandas(train)\n",
    "test = Dataset.from_pandas(test)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_train = train.map(tokenize_function)\n",
    "tokenized_test = test.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bea2bad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T08:38:41.113140Z",
     "start_time": "2022-12-09T08:38:37.941987Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/slivka_83/.cache/huggingface/hub/models--SkolkovoInstitute--russian_toxicity_classifier/snapshots/2b9a086ec05c2dc202fea11ed15f317b1676b18c/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"SkolkovoInstitute/russian_toxicity_classifier\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"neutral\",\n",
      "    \"1\": \"toxic\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"neutral\": 0,\n",
      "    \"toxic\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/slivka_83/.cache/huggingface/hub/models--SkolkovoInstitute--russian_toxicity_classifier/snapshots/2b9a086ec05c2dc202fea11ed15f317b1676b18c/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at SkolkovoInstitute/russian_toxicity_classifier.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'SkolkovoInstitute/russian_toxicity_classifier', \n",
    "    num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'test_trainer_log',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    per_device_train_batch_size = 6,\n",
    "    per_device_eval_batch_size = 6,\n",
    "    num_train_epochs = 5,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "metric = evaluate.load('f1')\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33074b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T08:42:47.008789Z",
     "start_time": "2022-12-09T08:38:42.501436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/slivka_83/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 700\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 585\n",
      "  Number of trainable parameters = 177854978\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='585' max='585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [585/585 04:04, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.401824</td>\n",
       "      <td>0.867580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.617232</td>\n",
       "      <td>0.855769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.696998</td>\n",
       "      <td>0.877828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708729</td>\n",
       "      <td>0.875576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.714718</td>\n",
       "      <td>0.875576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 300\n",
      "  Batch size = 6\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 300\n",
      "  Batch size = 6\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 300\n",
      "  Batch size = 6\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 300\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to test_trainer_log/checkpoint-500\n",
      "Configuration saved in test_trainer_log/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer_log/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, text. If __index_level_0__, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 300\n",
      "  Batch size = 6\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=585, training_loss=0.06792833231405443, metrics={'train_runtime': 244.4831, 'train_samples_per_second': 14.316, 'train_steps_per_second': 2.393, 'total_flos': 920888693760000.0, 'train_loss': 0.06792833231405443, 'epoch': 5.0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d645bfb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T20:00:24.130962Z",
     "start_time": "2022-11-28T20:00:22.897689Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./pt_save_pretrained/config.json\n",
      "Model weights saved in ./pt_save_pretrained/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "save_directory = './pt_save_pretrained'\n",
    "#tokenizer.save_pretrained(save_directory)\n",
    "model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc13df7",
   "metadata": {},
   "source": [
    "## torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf2413c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T09:42:53.690376Z",
     "start_time": "2022-12-09T09:42:50.376578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71cf1cdd3fd40cfbcc7efa76a301c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf0cb8aa1d6414ebc435f33e34e9274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "df = pd.read_csv('toxic.csv').sample(3_000)\n",
    "df.columns = ['text','label']\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train = Dataset.from_pandas(train)\n",
    "test = Dataset.from_pandas(test)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "def ds_preproc(ds):\n",
    "    ds = ds.map(tokenize_function)\n",
    "    ds = ds.remove_columns(['text', '__index_level_0__'])\n",
    "    ds = ds.rename_column('label', 'labels')\n",
    "    ds.set_format('torch')\n",
    "    return ds\n",
    "\n",
    "tokenized_train = ds_preproc(train)\n",
    "tokenized_test = ds_preproc(test)\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_train, shuffle=True, batch_size=8)\n",
    "test_dataloader = DataLoader(tokenized_test, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83744668",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T09:42:57.265934Z",
     "start_time": "2022-12-09T09:42:53.691623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'SkolkovoInstitute/russian_toxicity_classifier',\n",
    "    num_labels=2)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-7)\n",
    "\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name = 'linear', \n",
    "    optimizer = optimizer, \n",
    "    num_warmup_steps = 0, \n",
    "    num_training_steps = num_training_steps\n",
    ")\n",
    "\n",
    "device = 'cuda'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1e0a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T09:55:42.553570Z",
     "start_time": "2022-12-09T09:42:57.266831Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afa781d229444a5b4218dd1f1a31e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - {'f1': 0.8862559241706162}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - {'f1': 0.8941176470588236}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 - {'f1': 0.9018691588785047}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 - {'f1': 0.9018691588785047}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 - {'f1': 0.9018691588785047}\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader, leave=False):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    metric = evaluate.load('f1')\n",
    "    model.eval()\n",
    "    for batch in tqdm(test_dataloader, leave=False):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "    \n",
    "    print(f'epoch {epoch} -', metric.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e43204",
   "metadata": {},
   "source": [
    "## embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776dad06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T00:37:33.606552Z",
     "start_time": "2022-12-04T00:37:27.426775Z"
    }
   },
   "source": [
    "### sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.sbert.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9d9362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T09:59:20.448161Z",
     "start_time": "2022-12-09T09:59:11.927412Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/slivka_83/.cache/torch/sentence_transformers/SkolkovoInstitute_russian_toxicity_classifier. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /home/slivka_83/.cache/torch/sentence_transformers/SkolkovoInstitute_russian_toxicity_classifier were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.168708</td>\n",
       "      <td>-0.379199</td>\n",
       "      <td>0.288084</td>\n",
       "      <td>0.100402</td>\n",
       "      <td>0.412716</td>\n",
       "      <td>0.362394</td>\n",
       "      <td>0.127428</td>\n",
       "      <td>-0.517129</td>\n",
       "      <td>0.379522</td>\n",
       "      <td>-0.719490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061971</td>\n",
       "      <td>-0.007156</td>\n",
       "      <td>-0.701285</td>\n",
       "      <td>-0.724906</td>\n",
       "      <td>-0.102113</td>\n",
       "      <td>0.100030</td>\n",
       "      <td>-0.452336</td>\n",
       "      <td>-0.047709</td>\n",
       "      <td>0.368882</td>\n",
       "      <td>-0.322735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.045079</td>\n",
       "      <td>-0.097835</td>\n",
       "      <td>-0.479516</td>\n",
       "      <td>-0.319487</td>\n",
       "      <td>0.071947</td>\n",
       "      <td>-0.116214</td>\n",
       "      <td>1.176675</td>\n",
       "      <td>1.031475</td>\n",
       "      <td>-0.618434</td>\n",
       "      <td>-0.281351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314532</td>\n",
       "      <td>0.450745</td>\n",
       "      <td>-0.385783</td>\n",
       "      <td>0.696997</td>\n",
       "      <td>0.175919</td>\n",
       "      <td>-0.393985</td>\n",
       "      <td>0.645511</td>\n",
       "      <td>0.190868</td>\n",
       "      <td>0.157470</td>\n",
       "      <td>0.147497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.168708 -0.379199  0.288084  0.100402  0.412716  0.362394  0.127428   \n",
       "1 -0.045079 -0.097835 -0.479516 -0.319487  0.071947 -0.116214  1.176675   \n",
       "\n",
       "        7         8         9    ...       758       759       760       761  \\\n",
       "0 -0.517129  0.379522 -0.719490  ... -0.061971 -0.007156 -0.701285 -0.724906   \n",
       "1  1.031475 -0.618434 -0.281351  ...  0.314532  0.450745 -0.385783  0.696997   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0 -0.102113  0.100030 -0.452336 -0.047709  0.368882 -0.322735  \n",
       "1  0.175919 -0.393985  0.645511  0.190868  0.157470  0.147497  \n",
       "\n",
       "[2 rows x 768 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "\n",
    "text = ['У нас в есть убунты и текникал превью.',\n",
    "        'Как минимум два малолетних дегенерата в треде, мда.']\n",
    "\n",
    "embeddings = model.encode(text)\n",
    "\n",
    "df = pd.DataFrame(embeddings)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8dc9c",
   "metadata": {},
   "source": [
    "### Усреднение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af146296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T09:59:21.794197Z",
     "start_time": "2022-12-09T09:59:20.449426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.074600</td>\n",
       "      <td>-0.233042</td>\n",
       "      <td>-0.084994</td>\n",
       "      <td>0.076429</td>\n",
       "      <td>0.215108</td>\n",
       "      <td>0.662372</td>\n",
       "      <td>0.160069</td>\n",
       "      <td>-0.172681</td>\n",
       "      <td>0.193040</td>\n",
       "      <td>-0.431338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307956</td>\n",
       "      <td>0.136790</td>\n",
       "      <td>-0.092838</td>\n",
       "      <td>-0.067860</td>\n",
       "      <td>0.173766</td>\n",
       "      <td>0.075278</td>\n",
       "      <td>-0.084738</td>\n",
       "      <td>0.544805</td>\n",
       "      <td>0.672492</td>\n",
       "      <td>-0.230025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.260372</td>\n",
       "      <td>0.253684</td>\n",
       "      <td>0.144730</td>\n",
       "      <td>0.156579</td>\n",
       "      <td>-0.163387</td>\n",
       "      <td>0.384969</td>\n",
       "      <td>0.456058</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>-0.030840</td>\n",
       "      <td>-0.035321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125319</td>\n",
       "      <td>-0.011805</td>\n",
       "      <td>0.141031</td>\n",
       "      <td>-0.213023</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>-0.168322</td>\n",
       "      <td>0.314002</td>\n",
       "      <td>0.306754</td>\n",
       "      <td>0.391649</td>\n",
       "      <td>-0.153518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.238290</td>\n",
       "      <td>0.319653</td>\n",
       "      <td>0.261314</td>\n",
       "      <td>0.420612</td>\n",
       "      <td>0.145059</td>\n",
       "      <td>-0.204098</td>\n",
       "      <td>-0.014130</td>\n",
       "      <td>-0.325124</td>\n",
       "      <td>-0.013538</td>\n",
       "      <td>0.119720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.356111</td>\n",
       "      <td>-0.029595</td>\n",
       "      <td>-0.101007</td>\n",
       "      <td>-0.342510</td>\n",
       "      <td>-0.210141</td>\n",
       "      <td>0.188064</td>\n",
       "      <td>0.301274</td>\n",
       "      <td>0.282925</td>\n",
       "      <td>0.304315</td>\n",
       "      <td>0.553583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.074600 -0.233042 -0.084994  0.076429  0.215108  0.662372  0.160069   \n",
       "1  0.260372  0.253684  0.144730  0.156579 -0.163387  0.384969  0.456058   \n",
       "2  0.238290  0.319653  0.261314  0.420612  0.145059 -0.204098 -0.014130   \n",
       "\n",
       "        7         8         9    ...       374       375       376       377  \\\n",
       "0 -0.172681  0.193040 -0.431338  ...  0.307956  0.136790 -0.092838 -0.067860   \n",
       "1  0.033556 -0.030840 -0.035321  ...  0.125319 -0.011805  0.141031 -0.213023   \n",
       "2 -0.325124 -0.013538  0.119720  ... -0.356111 -0.029595 -0.101007 -0.342510   \n",
       "\n",
       "        378       379       380       381       382       383  \n",
       "0  0.173766  0.075278 -0.084738  0.544805  0.672492 -0.230025  \n",
       "1  0.021587 -0.168322  0.314002  0.306754  0.391649 -0.153518  \n",
       "2 -0.210141  0.188064  0.301274  0.282925  0.304315  0.553583  \n",
       "\n",
       "[3 rows x 384 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "#Sentences we want sentence embeddings for\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "             'Sentences are passed as a list of string.',\n",
    "             'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "#Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "#Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "df = pd.DataFrame(sentence_embeddings).astype('float')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5441e37d",
   "metadata": {},
   "source": [
    "# Токенвйзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "592d2b98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T00:11:12.978375Z",
     "start_time": "2022-12-09T00:11:12.316341Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b16a35f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T00:11:12.983003Z",
     "start_time": "2022-12-09T00:11:12.979687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['У',\n",
       " 'нас',\n",
       " 'в',\n",
       " 'есть',\n",
       " 'убу',\n",
       " '##нты',\n",
       " 'и',\n",
       " 'тек',\n",
       " '##ника',\n",
       " '##л',\n",
       " 'превью',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('У нас в есть убунты и текникал превью.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03493eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T00:11:30.582660Z",
     "start_time": "2022-12-09T00:11:30.578100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 486, 1159, 340, 999, 63692, 10285, 322, 3100, 1352, 343, 85379, 132, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer('У нас в есть убунты и текникал превью.')\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fb8baf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T00:11:44.757782Z",
     "start_time": "2022-12-09T00:11:44.753679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] У нас в есть убунты и текникал превью. [SEP]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73c7f870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T00:00:18.899129Z",
     "start_time": "2022-12-06T00:00:18.894066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 486, 1159, 340, 999, 63692, 10285, 102, 0, 0, 0, 0, 0], [101, 1235, 3932, 1617, 53502, 97527, 303, 340, 39685, 128, 48557, 132, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['У нас в есть убунты',\n",
    "        'Как минимум два малолетних дегенерата в треде, мда.']\n",
    "\n",
    "encoding = tokenizer(\n",
    "    text, \n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e56385",
   "metadata": {},
   "source": [
    "# ImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af55c5a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T09:59:23.816419Z",
     "start_time": "2022-12-09T09:59:21.795119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[ 0.4275,  0.4275,  0.4196,  ...,  0.0902,  0.1216,  0.0667],\n",
       "          [ 0.4431,  0.4353,  0.4118,  ...,  0.0902,  0.0588,  0.0118],\n",
       "          [ 0.4431,  0.4353,  0.4039,  ...,  0.1686,  0.1059,  0.0431],\n",
       "          ...,\n",
       "          [-0.1373, -0.0745, -0.0431,  ...,  0.2941,  0.2863,  0.2627],\n",
       "          [-0.1529, -0.1137, -0.0588,  ...,  0.2784,  0.2627,  0.2627],\n",
       "          [-0.1529, -0.1294, -0.0745,  ...,  0.2706,  0.2392,  0.2392]],\n",
       "\n",
       "         [[ 0.4275,  0.4431,  0.4588,  ...,  0.0275,  0.0667,  0.0588],\n",
       "          [ 0.4431,  0.4510,  0.4510,  ...,  0.0275,  0.0039,  0.0039],\n",
       "          [ 0.4431,  0.4431,  0.4431,  ...,  0.1059,  0.0510,  0.0275],\n",
       "          ...,\n",
       "          [-0.2392, -0.1765, -0.1451,  ...,  0.1922,  0.1922,  0.1765],\n",
       "          [-0.2549, -0.2157, -0.1608,  ...,  0.1765,  0.1765,  0.1922],\n",
       "          [-0.2549, -0.2314, -0.1765,  ...,  0.1686,  0.1529,  0.1765]],\n",
       "\n",
       "         [[ 0.4431,  0.4510,  0.4275,  ..., -0.0902, -0.0824, -0.0980],\n",
       "          [ 0.4588,  0.4588,  0.4275,  ..., -0.0980, -0.1451, -0.1529],\n",
       "          [ 0.4588,  0.4510,  0.4118,  ..., -0.0196, -0.0980, -0.1294],\n",
       "          ...,\n",
       "          [-0.3647, -0.3020, -0.2706,  ...,  0.0667,  0.0667,  0.0510],\n",
       "          [-0.3804, -0.3490, -0.2941,  ...,  0.0431,  0.0353,  0.0431],\n",
       "          [-0.3882, -0.3647, -0.3098,  ...,  0.0353,  0.0118,  0.0275]]]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "response = requests.get(\n",
    "    'https://github.com/laxmimerit/dog-cat-full-dataset/blob/master/data/train/cats/cat.10055.jpg?raw=true')\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "inputs = image_processor(img, return_tensors='pt')\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef0db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
